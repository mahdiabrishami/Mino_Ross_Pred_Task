{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Prediction for 6 weeks and for over 1000 stores around Germany\n",
    "In this file, a process of data cleaning and imputing NaN values, as well as data modelling and prediction has been done. Although, not a part of this file, I guess, imputing values of the 6 months sales for 180 stores, according to their historical values could also improve the model.\n",
    "\n",
    "The 3 different data sets, imported in this file, include the historical sale data (train), store attributes (store) and the data for 6 weeks of sales prediction (test).\n",
    "\n",
    "For data modelling, extreme gradient boosting approach (recommended by many kaggle competetors) is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the essential libraries\n",
    "import pandas as pd\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pylab as pl\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:...\\data\\train.csv', header=0, dtype={'StateHoliday':'str'})\n",
    "store = pd.read_csv(r'C:...\\data\\store.csv', header=0)\n",
    "test = ds = pd.read_csv(r'C:...\\data\\test.csv', header=0, dtype={'StateHoliday':'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = [x.lower() for x in train.columns]\n",
    "store.columns = [x.lower() for x in store.columns]\n",
    "test.columns = [x.lower() for x in test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I consider some attributes for data modelling\n",
    "train = train.drop(['stateholiday','schoolholiday'], axis = 1)\n",
    "test = test.drop(['stateholiday','schoolholiday'], axis = 1)\n",
    "store = store.drop(['competitionopensincemonth','competitionopensinceyear','promo2','promo2sinceweek',\n",
    "                    'promo2sinceyear','promointerval'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both test and train on the store\n",
    "train = pd.merge(train,store, on='store')\n",
    "test = pd.merge(test,store, on='store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important to change all the associting attributes for data modelling into numerical attributes\n",
    "replace_alph_numer = {'assortment': {'a':1,'b':2,'c':3},\n",
    "                      'storetype': {'a':1,'b':2,'c':3,'d':4}}\n",
    "train.replace(replace_alph_numer,inplace= True)\n",
    "test.replace(replace_alph_numer, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I extract the year, month and day for each row from the date for both test and train data\n",
    "train['year'] = train.date.apply(lambda x: x.split('-'))\n",
    "train['month'] = train.year.apply(lambda x: int(x[1]))\n",
    "train['day'] = train.year.apply(lambda x: int(x[2]))\n",
    "train['year'] = train.year.apply(lambda x: int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['year'] = test.date.apply(lambda x: x.split('-'))\n",
    "test['month'] = test.year.apply(lambda x: int(x[1]))\n",
    "test['day'] = test.year.apply(lambda x: int(x[2]))\n",
    "test['year'] = test.year.apply(lambda x: int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.date = pd.to_datetime(train.date)\n",
    "test.date = pd.to_datetime(test.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'pandas._libs.tslib.Timestamp'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for col in test:\n",
    "    print(type(test[col][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>storetype</th>\n",
       "      <th>assortment</th>\n",
       "      <th>competitiondistance</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41077.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>40992.000000</td>\n",
       "      <td>41088.0</td>\n",
       "      <td>41088.000000</td>\n",
       "      <td>41088.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20544.500000</td>\n",
       "      <td>555.899533</td>\n",
       "      <td>3.979167</td>\n",
       "      <td>0.854322</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>2.252336</td>\n",
       "      <td>2.001168</td>\n",
       "      <td>5088.583138</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.354167</td>\n",
       "      <td>13.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11861.228267</td>\n",
       "      <td>320.274496</td>\n",
       "      <td>2.015481</td>\n",
       "      <td>0.352787</td>\n",
       "      <td>0.489035</td>\n",
       "      <td>1.397401</td>\n",
       "      <td>0.994741</td>\n",
       "      <td>7225.487467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478266</td>\n",
       "      <td>8.448450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10272.750000</td>\n",
       "      <td>279.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20544.500000</td>\n",
       "      <td>553.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2425.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30816.250000</td>\n",
       "      <td>832.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6480.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41088.000000</td>\n",
       "      <td>1115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>75860.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         store     dayofweek          open         promo  \\\n",
       "count  41088.000000  41088.000000  41088.000000  41077.000000  41088.000000   \n",
       "mean   20544.500000    555.899533      3.979167      0.854322      0.395833   \n",
       "std    11861.228267    320.274496      2.015481      0.352787      0.489035   \n",
       "min        1.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%    10272.750000    279.750000      2.000000      1.000000      0.000000   \n",
       "50%    20544.500000    553.500000      4.000000      1.000000      0.000000   \n",
       "75%    30816.250000    832.250000      6.000000      1.000000      1.000000   \n",
       "max    41088.000000   1115.000000      7.000000      1.000000      1.000000   \n",
       "\n",
       "          storetype    assortment  competitiondistance     year         month  \\\n",
       "count  41088.000000  41088.000000         40992.000000  41088.0  41088.000000   \n",
       "mean       2.252336      2.001168          5088.583138   2015.0      8.354167   \n",
       "std        1.397401      0.994741          7225.487467      0.0      0.478266   \n",
       "min        1.000000      1.000000            20.000000   2015.0      8.000000   \n",
       "25%        1.000000      1.000000           720.000000   2015.0      8.000000   \n",
       "50%        1.000000      2.000000          2425.000000   2015.0      8.000000   \n",
       "75%        4.000000      3.000000          6480.000000   2015.0      9.000000   \n",
       "max        4.000000      3.000000         75860.000000   2015.0      9.000000   \n",
       "\n",
       "                day  \n",
       "count  41088.000000  \n",
       "mean      13.520833  \n",
       "std        8.448450  \n",
       "min        1.000000  \n",
       "25%        6.750000  \n",
       "50%       12.500000  \n",
       "75%       19.250000  \n",
       "max       31.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have missing values in 'open' column as well as 'competitiondistance'\n",
    "test.loc[test.open.isnull(), 'open'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "store                  0\n",
       "dayofweek              0\n",
       "date                   0\n",
       "open                   0\n",
       "promo                  0\n",
       "storetype              0\n",
       "assortment             0\n",
       "competitiondistance    0\n",
       "year                   0\n",
       "month                  0\n",
       "day                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace NaN values with 0 in both train and test \n",
    "test.fillna(0,inplace = True)\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume that stores that had no sale, but announced open, have been closed.\n",
    "train.loc[(train.open == 1)&(train.sales == 0), 'open'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                  0\n",
       "dayofweek              0\n",
       "date                   0\n",
       "sales                  0\n",
       "customers              0\n",
       "open                   0\n",
       "promo                  0\n",
       "storetype              0\n",
       "assortment             0\n",
       "competitiondistance    0\n",
       "year                   0\n",
       "month                  0\n",
       "day                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.fillna(0,inplace = True)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I drop some more columns for modelling\n",
    "train = train.drop(['date','customers'],axis=1)\n",
    "test = test.drop(['date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# courtesy of Chenglong Chen from Kaggle forum\n",
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def ToZero(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y > 0\n",
    "    w[ind] = y[ind]\n",
    "    return w\n",
    "\n",
    "def rmspe(ytest, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w*(y-ytest)**2 ))\n",
    "    return rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def error_evaluation(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    y = [math.exp(x)-1 for x in labels[labels > 0]]\n",
    "    yhat = [math.exp(x)-1 for x in preds[labels > 0]]\n",
    "    ssquare = [math.pow((y[i] - yhat[i])/y[i],2) for i in range(len(y))]\n",
    "    return 'rmpse', math.sqrt(np.mean(ssquare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.drop('sales', axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters for xgboost\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"eta\": 0.25,\n",
    "          \"max_depth\": 10,\n",
    "          \"silent\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"seed\": 1,\n",
    "          \"booster\": \"gbtree\"}\n",
    "num_trees = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I split the train data into test and train for cross validation\n",
    "from sklearn import cross_validation\n",
    "X_train, X_test = cross_validation.train_test_split(train,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I set the DMatrix for prediction as well as having a watchlist, while running the training\n",
    "dtrain = xgb.DMatrix(X_train[features], np.log(X_train[\"sales\"] + 1))\n",
    "dvalid = xgb.DMatrix(X_test[features], np.log(X_test[\"sales\"] + 1))\n",
    "dtest = xgb.DMatrix(test[features])\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:5.65991\ttrain-rmse:5.65632\teval-rmpse:0.997949\ttrain-rmpse:0.99795\n",
      "Multiple eval metrics have been passed: 'train-rmpse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmpse hasn't improved in 25 rounds.\n",
      "[5]\teval-rmse:1.3753\ttrain-rmse:1.37475\teval-rmpse:0.763071\ttrain-rmpse:0.761868\n",
      "[10]\teval-rmse:0.42967\ttrain-rmse:0.429556\teval-rmpse:0.386655\ttrain-rmpse:0.362551\n",
      "[15]\teval-rmse:0.280966\ttrain-rmse:0.28056\teval-rmpse:0.353489\ttrain-rmpse:0.310144\n",
      "[20]\teval-rmse:0.251396\ttrain-rmse:0.250796\teval-rmpse:0.35687\ttrain-rmpse:0.308797\n",
      "[25]\teval-rmse:0.228911\ttrain-rmse:0.228097\teval-rmpse:0.341954\ttrain-rmpse:0.289782\n",
      "[30]\teval-rmse:0.209107\ttrain-rmse:0.208378\teval-rmpse:0.324683\ttrain-rmpse:0.26796\n",
      "[35]\teval-rmse:0.195218\ttrain-rmse:0.194219\teval-rmpse:0.311654\ttrain-rmpse:0.246028\n",
      "[40]\teval-rmse:0.185905\ttrain-rmse:0.184787\teval-rmpse:0.303389\ttrain-rmpse:0.234677\n",
      "[45]\teval-rmse:0.179269\ttrain-rmse:0.177923\teval-rmpse:0.306712\ttrain-rmpse:0.225578\n",
      "[50]\teval-rmse:0.167435\ttrain-rmse:0.165971\teval-rmpse:0.295925\ttrain-rmpse:0.211808\n",
      "[55]\teval-rmse:0.158078\ttrain-rmse:0.156403\teval-rmpse:0.287423\ttrain-rmpse:0.200419\n",
      "[60]\teval-rmse:0.152761\ttrain-rmse:0.150876\teval-rmpse:0.288852\ttrain-rmpse:0.190043\n",
      "[65]\teval-rmse:0.145399\ttrain-rmse:0.143145\teval-rmpse:0.283207\ttrain-rmpse:0.181266\n",
      "[70]\teval-rmse:0.141148\ttrain-rmse:0.138684\teval-rmpse:0.280462\ttrain-rmpse:0.174205\n",
      "[75]\teval-rmse:0.137827\ttrain-rmse:0.135155\teval-rmpse:0.2774\ttrain-rmpse:0.17001\n",
      "[80]\teval-rmse:0.134373\ttrain-rmse:0.131469\teval-rmpse:0.275328\ttrain-rmpse:0.162454\n",
      "[85]\teval-rmse:0.130266\ttrain-rmse:0.127158\teval-rmpse:0.27243\ttrain-rmpse:0.157323\n",
      "[90]\teval-rmse:0.125931\ttrain-rmse:0.122433\teval-rmpse:0.268814\ttrain-rmpse:0.151547\n",
      "[95]\teval-rmse:0.123847\ttrain-rmse:0.120228\teval-rmpse:0.267555\ttrain-rmpse:0.149339\n",
      "[100]\teval-rmse:0.121222\ttrain-rmse:0.117423\teval-rmpse:0.270131\ttrain-rmpse:0.145839\n",
      "[105]\teval-rmse:0.118376\ttrain-rmse:0.114293\teval-rmpse:0.268719\ttrain-rmpse:0.141337\n",
      "[110]\teval-rmse:0.117205\ttrain-rmse:0.112986\teval-rmpse:0.274528\ttrain-rmpse:0.13948\n",
      "[115]\teval-rmse:0.115968\ttrain-rmse:0.111627\teval-rmpse:0.272849\ttrain-rmpse:0.137977\n",
      "[120]\teval-rmse:0.114366\ttrain-rmse:0.109893\teval-rmpse:0.27199\ttrain-rmpse:0.136074\n",
      "[125]\teval-rmse:0.112798\ttrain-rmse:0.108108\teval-rmpse:0.271463\ttrain-rmpse:0.133837\n",
      "[130]\teval-rmse:0.111184\ttrain-rmse:0.106331\teval-rmpse:0.269225\ttrain-rmpse:0.131478\n",
      "[135]\teval-rmse:0.10988\ttrain-rmse:0.104838\teval-rmpse:0.268323\ttrain-rmpse:0.129645\n",
      "[140]\teval-rmse:0.108807\ttrain-rmse:0.103562\teval-rmpse:0.267702\ttrain-rmpse:0.128235\n",
      "[145]\teval-rmse:0.108036\ttrain-rmse:0.102658\teval-rmpse:0.267897\ttrain-rmpse:0.127085\n",
      "[150]\teval-rmse:0.107192\ttrain-rmse:0.101573\teval-rmpse:0.267413\ttrain-rmpse:0.125656\n",
      "[155]\teval-rmse:0.105742\ttrain-rmse:0.09991\teval-rmpse:0.266452\ttrain-rmpse:0.123707\n",
      "[160]\teval-rmse:0.105269\ttrain-rmse:0.099312\teval-rmpse:0.265464\ttrain-rmpse:0.122746\n",
      "[165]\teval-rmse:0.104002\ttrain-rmse:0.097906\teval-rmpse:0.264989\ttrain-rmpse:0.121189\n",
      "[170]\teval-rmse:0.102974\ttrain-rmse:0.096703\teval-rmpse:0.264337\ttrain-rmpse:0.119783\n",
      "[175]\teval-rmse:0.102221\ttrain-rmse:0.09579\teval-rmpse:0.263888\ttrain-rmpse:0.118692\n",
      "[180]\teval-rmse:0.101355\ttrain-rmse:0.094738\teval-rmpse:0.263542\ttrain-rmpse:0.117007\n",
      "[185]\teval-rmse:0.100676\ttrain-rmse:0.093873\teval-rmpse:0.263312\ttrain-rmpse:0.11589\n",
      "[190]\teval-rmse:0.100073\ttrain-rmse:0.093062\teval-rmpse:0.263028\ttrain-rmpse:0.114839\n",
      "[195]\teval-rmse:0.09964\ttrain-rmse:0.092424\teval-rmpse:0.264111\ttrain-rmpse:0.113885\n",
      "[200]\teval-rmse:0.099124\ttrain-rmse:0.091737\teval-rmpse:0.263802\ttrain-rmpse:0.113033\n",
      "[205]\teval-rmse:0.098618\ttrain-rmse:0.09103\teval-rmpse:0.267325\ttrain-rmpse:0.112168\n",
      "[210]\teval-rmse:0.098195\ttrain-rmse:0.090359\teval-rmpse:0.267217\ttrain-rmpse:0.111175\n",
      "[215]\teval-rmse:0.097642\ttrain-rmse:0.089598\teval-rmpse:0.267924\ttrain-rmpse:0.110309\n",
      "[220]\teval-rmse:0.097083\ttrain-rmse:0.088901\teval-rmpse:0.267642\ttrain-rmpse:0.109501\n",
      "[225]\teval-rmse:0.096841\ttrain-rmse:0.088437\teval-rmpse:0.267537\ttrain-rmpse:0.108854\n",
      "[230]\teval-rmse:0.096392\ttrain-rmse:0.087738\teval-rmpse:0.267698\ttrain-rmpse:0.108018\n",
      "[235]\teval-rmse:0.09608\ttrain-rmse:0.08725\teval-rmpse:0.268037\ttrain-rmpse:0.107354\n",
      "[240]\teval-rmse:0.095663\ttrain-rmse:0.086639\teval-rmpse:0.270946\ttrain-rmpse:0.106488\n",
      "[245]\teval-rmse:0.095348\ttrain-rmse:0.086167\teval-rmpse:0.271093\ttrain-rmpse:0.105739\n",
      "[250]\teval-rmse:0.094995\ttrain-rmse:0.085632\teval-rmpse:0.270893\ttrain-rmpse:0.105085\n",
      "[255]\teval-rmse:0.094769\ttrain-rmse:0.085263\teval-rmpse:0.271717\ttrain-rmpse:0.104601\n",
      "[260]\teval-rmse:0.094538\ttrain-rmse:0.08483\teval-rmpse:0.271796\ttrain-rmpse:0.104038\n",
      "[265]\teval-rmse:0.094189\ttrain-rmse:0.084353\teval-rmpse:0.271712\ttrain-rmpse:0.103403\n",
      "[270]\teval-rmse:0.093872\ttrain-rmse:0.083834\teval-rmpse:0.270972\ttrain-rmpse:0.102711\n",
      "[275]\teval-rmse:0.093657\ttrain-rmse:0.083471\teval-rmpse:0.271045\ttrain-rmpse:0.102274\n",
      "[280]\teval-rmse:0.093476\ttrain-rmse:0.083128\teval-rmpse:0.270917\ttrain-rmpse:0.10181\n",
      "[285]\teval-rmse:0.093326\ttrain-rmse:0.082771\teval-rmpse:0.270599\ttrain-rmpse:0.101232\n",
      "[290]\teval-rmse:0.093205\ttrain-rmse:0.08241\teval-rmpse:0.270431\ttrain-rmpse:0.100755\n",
      "[295]\teval-rmse:0.093002\ttrain-rmse:0.082032\teval-rmpse:0.270285\ttrain-rmpse:0.100276\n",
      "[300]\teval-rmse:0.092735\ttrain-rmse:0.081614\teval-rmpse:0.269934\ttrain-rmpse:0.099636\n",
      "[305]\teval-rmse:0.092589\ttrain-rmse:0.081328\teval-rmpse:0.270033\ttrain-rmpse:0.099254\n",
      "[310]\teval-rmse:0.092326\ttrain-rmse:0.080876\teval-rmpse:0.269935\ttrain-rmpse:0.098205\n",
      "[315]\teval-rmse:0.092086\ttrain-rmse:0.080467\teval-rmpse:0.2698\ttrain-rmpse:0.097729\n",
      "[320]\teval-rmse:0.09189\ttrain-rmse:0.080143\teval-rmpse:0.26983\ttrain-rmpse:0.097352\n",
      "[325]\teval-rmse:0.091728\ttrain-rmse:0.079764\teval-rmpse:0.269962\ttrain-rmpse:0.096848\n",
      "[330]\teval-rmse:0.09158\ttrain-rmse:0.079459\teval-rmpse:0.269959\ttrain-rmpse:0.096497\n",
      "[335]\teval-rmse:0.091407\ttrain-rmse:0.079147\teval-rmpse:0.269873\ttrain-rmpse:0.096037\n",
      "[340]\teval-rmse:0.091282\ttrain-rmse:0.078892\teval-rmpse:0.269459\ttrain-rmpse:0.095676\n",
      "[345]\teval-rmse:0.091146\ttrain-rmse:0.078553\teval-rmpse:0.269602\ttrain-rmpse:0.094814\n",
      "[350]\teval-rmse:0.091022\ttrain-rmse:0.078221\teval-rmpse:0.269515\ttrain-rmpse:0.094312\n",
      "[355]\teval-rmse:0.090853\ttrain-rmse:0.077918\teval-rmpse:0.269731\ttrain-rmpse:0.09396\n",
      "[360]\teval-rmse:0.090789\ttrain-rmse:0.077694\teval-rmpse:0.269498\ttrain-rmpse:0.093621\n",
      "[365]\teval-rmse:0.090703\ttrain-rmse:0.077433\teval-rmpse:0.269818\ttrain-rmpse:0.093155\n",
      "[370]\teval-rmse:0.090657\ttrain-rmse:0.077185\teval-rmpse:0.269827\ttrain-rmpse:0.092393\n",
      "[375]\teval-rmse:0.09059\ttrain-rmse:0.076944\teval-rmpse:0.270083\ttrain-rmpse:0.092036\n",
      "[380]\teval-rmse:0.0905\ttrain-rmse:0.076655\teval-rmpse:0.270248\ttrain-rmpse:0.091642\n",
      "[385]\teval-rmse:0.090423\ttrain-rmse:0.076432\teval-rmpse:0.270217\ttrain-rmpse:0.091356\n",
      "[390]\teval-rmse:0.090309\ttrain-rmse:0.076156\teval-rmpse:0.26968\ttrain-rmpse:0.090931\n",
      "[395]\teval-rmse:0.090207\ttrain-rmse:0.075934\teval-rmpse:0.269915\ttrain-rmpse:0.090644\n",
      "[399]\teval-rmse:0.090127\ttrain-rmse:0.07573\teval-rmpse:0.26982\ttrain-rmpse:0.090382\n"
     ]
    }
   ],
   "source": [
    "#I perform the training, with the following attributes. We can see the output in every 5 rounds, while the model will stop\n",
    "#if there is no improvement after 25 rounds\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, early_stopping_rounds=25, verbose_eval=5, feval=error_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Validation in Process\n",
      "0.245963696278\n"
     ]
    }
   ],
   "source": [
    "# We calculate the model error for the splitted set from train and according to predicted values from the model and real values\n",
    "# from train data set\n",
    "print(\"Model Validation in Process\")\n",
    "train_probs = gbm.predict(xgb.DMatrix(X_test[features]))\n",
    "error = rmspe(np.exp(train_probs) - 1, X_test['sales'].values)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform the prediction on the test data set\n",
    "real_test = gbm.predict(xgb.DMatrix(test[features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41088"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a data frame for the predicted values\n",
    "sale_forecast = pd.DataFrame({\"id\": test[\"id\"], \"sales\": np.exp(ToZero(real_test)) - 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predicted values in a csv format file\n",
    "sale_forecast.to_csv(\"some_file.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
